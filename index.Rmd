---
title: "Spotify Playlist Analysis with Python"
author: "Hannah Luebbering"
date: "July 04, 2022"
output: 
  html_document: 
    css: "assets/main2.css"
    toc: yes
    toc_float: yes
knit: (function(inputFile, encoding) {rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })
bibliography: assets/references.bib
nocite: '@*'
csl: assets/advanced-optical-materials.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, out.width = "80%")
library(kableExtra)
library(knitr)
library(ggplot2)
library(hrbrthemes)
library(lubridate)
library(GGally)
library(ggrepel)
library(spotifyr)
library(tidyverse)
library(shiny)
library(shinydashboard)
library(magick)
library(genius)
library(tidytext)
library(geniusr)
library(dplyr)

# source('scripts/data.R')
```



<script src="assets/min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="assets/pymin.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




<span class = "myhighlight">Objective.</span> Using Python, the goal of this project is to implement the k-means clustering algorithm, a technique often used in machine learning, and use it for data analysis. We write various functions using lists, sets, dictionaries, sorting, and graph data structures for computational problem-solving and analysis.













-------------------------



## Part 1. Spotify API Data


Spotify is a popular audio streaming platform with an extensive music database. The Spotify API allows developers to access the platform's data providing global insights into music listening habits around the world [@WebAPIReference2022]. Using the API requires an initial setup involving several steps. These steps include registering as a Spotify developer, creating an app, modifying the dashboard redirect URI, and storing the client ID and secret. After completing the initial steps for setup, we have access to the Spotify API and all its features. 



### Get Playlist Data from API


First, we create a Client Credentials Flow Manager used in server-to-server authentication by passing the necessary parameters to the [Spotify OAuth](https://github.com/spotipy-dev/spotipy/blob/master/spotipy/oauth2.py#L261) class [@WelcomeSpotipySpotipy2022]. We provide a client id and client secret to the constructor of this authorization flow, which does not require user interaction.




```python
# Set client id and client secret
client_id = 'xxx'
client_secret = 'xxx'

# Spotify authentication
client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)
sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)
```


Now we can get the full details of the tracks of a playlist based on a playlist ID, URI, or URL. Choose a specific playlist to analyze by copying the URL from the Spotify Player interface. Using that link, the following code uses the playlist_tracks method to retrieve a list of IDs and corresponding artists for each track from the playlist. 


```python
for link in playlist_links:
    playlist_URI = link.split("/")[-1].split("?")[0]
    # Iterate over list of tracks in playlist
    for i in sp.playlist_tracks(playlist_URI)["items"]:   
        track_ids.append(i['track']["id"]) # Extract song id
        artist_ids.append(i['track']["artists"][0]["uri"]) # Extract artist id
```






Then, we [write a function](https://github.com/hluebbering/playlist_report/blob/main/scripts/spotify_data.py) that takes the playlist data from the API and gets the metadata and audio characteristics of each track. Specifically, the function reads the query results for a playlist and returns the track name, track ID, artist, album, duration, popularity, artist popularity, artist genre, and audio characteristics for each track.




- `name`: The name of the track.
- `album`: The name of the album on which the track appears.
- `artist`: The name of the artist who performed the track.
- `release_date`: The date the album was first released.
- `length`: The track length in milliseconds.
- `popularity`: The popularity of the track calculated by an algorithm based on the total number of plays the track has had and how recent those plays are.
- `artist_pop`: The popularity of the artist calculated from the popularity of all the artist's tracks.
- `artist_genres`: A list of the genres the artist is associated with.



#### Spotify Audio Features


Spotify’s audio features are precalculated measures of both low-level and high-level perceptual music qualities that help classify a track. As indicated by the Spotify website, a quick explanation of each feature is shown below. More information on how to interpret these audio features is located at [Spotify’s API documentation](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features).



- `acousticness`: A confidence measure of whether the track is acoustic.
- `danceability`: Suitability for dancing based on tempo, rhythm, beat, and regularity.
- `energy`: A perceptual measure of intensity and activity.
- `instrumentalness`: Predicts whether a track contains no vocals.
- `liveness`: Probability that the track was performed live.
- `loudness`: Overall loudness of a track in decibels (dB).
- `speechiness`: Detects the presence of spoken words in a track.
- `tempo`: Estimated pace of a track in beats per minute (BPM).
- `valence`: A measure describing the musical positiveness.






The following code loops through each track ID in the playlist and extracts the song information by calling the function we created. From there, we can create a dataframe by passing in the returned data using the pandas package. 


```python
# Loop over track ids
all_tracks = [playlist_features(track_ids[i], artist_ids[i], playlist_ids[i]) 
              for i in range(len(track_ids))]
```



```{r}
df <- read.csv('scripts/data/my_playlist.csv')
my_cols <- c('name','album','artist','release_date','length','popularity','artist_pop','artist_genres','acousticness','danceability','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence')
df <- dplyr::select(df, my_cols)

head(df, 2) %>% kable() %>% kable_styling() %>%
  column_spec(c(1:16), width_max = "3cm") %>%
  scroll_box(width = "100%")
```




```{r}
library(reticulate)
reticulate::source_python('scripts/all_functions.py')
```











-------------------------


## Part 2. Similar Artists


First, we want to find the most frequently occurring artist in a given playlist. We use the value_counts function to get a sequence containing counts of unique values sorted in descending order. 


```{python, echo=TRUE}
# Count distinct values in column
tallyArtists = df.value_counts(["artist", "artist_id"]).reset_index(name='counts')
topArtist = tallyArtists['artist_id'][1]
```


```{r}
py$tallyArtists %>% head(3) %>% kable() %>% kable_styling()
```




I can retrieve artist and artist-related data using the following code, passing the artist ID to the artist and artist-related artist functions under the spotipy package. The returned list of similar artists is sorted by similarity score based on the listener data [@webbVisualizingRapCommunities2020].




```{python, echo=TRUE}
a = sp.artist(topArtist)
ra = sp.artist_related_artists(topArtist)
```





```{python}
# dictionary of lists 
links_dict = {"source_name":[],"source_id":[],"target_name":[],"target_id":[]};
for artist in ra['artists']:
    links_dict["source_name"].append(a['name'])
    links_dict["source_id"].append(a['id'])
    links_dict["target_name"].append(artist['name'])
    links_dict["target_id"].append(artist['id'])
```



Below is a sample of the result when we query Spotify for the most similar artists to the playlist's top artist, creating a list that holds all of the artist source ids and target ids. We retrieve similar data for the nodes of the connection graph, creating a list that holds information for each specified artist.



```{r}
py$links_dict %>% data.frame() %>% head(3) %>% kable() %>% kable_styling()
```



\ 


Let’s see how things look when we pull in the full dataset, with each of the artist's top most similar artists and each of their most similar artists. The following visualization is based on the [Spotify Similiar Artists API](https://unboxed-analytics.com/data-technology/visualizing-rap-communities-wtih-python-spotifys-api/) article and created with flourish studio.




<iframe src='https://flo.uri.sh/visualisation/12278724/embed' title='Interactive or visual content' class='flourish-embed-iframe' frameborder='0' scrolling='no' style='width:100%;height:400px;' sandbox='allow-same-origin allow-forms allow-scripts allow-downloads allow-popups allow-popups-to-escape-sandbox allow-top-navigation-by-user-activation'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/12278724/?utm_source=embed&utm_campaign=visualisation/12278724' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>



-------------------------



## Part 3. Track Similarity Search



<span class = "myhighlight">Objective.</span> Design and implement a k-means clustering algorithm in Python.


K-means clustering is a popular machine learning and data mining algorithm that discovers possible clusters within a dataset. Finding these clusters often reveals meaningful information from the data distribution. Below, we create a query to retrieve similar elements based on the k-Nearest Neighbors (KNN) using the Euclidean distance.



### Definitions


As with many machine learning techniques, this algorithm consists of a vast list of terminology which we define in a bit more detail below.


<span class = "myhighlight2">Definition 1. Distance</span> The Euclidean distance, which indicates a straight line, is a simple way to calculate how close a data point is to a centroid using the Pythagorean theorem. For two points $a = \left[a_1, a_2, \ldots, a_n\right]$ and $b = \left[b_1, b_2, \ldots, b_n\right]$, where $n$ is the current dimension, we define the euclidean distance between both points as 


$$
\small
\begin{align}
\mathbf{\color{darkmagenta} D}(a, b) &= 
\sqrt{\left(a_1 - b_1\right)^2 + 
\left(a_2 - b_2\right)^2 + 
\ldots + \left(a_n - b_n\right)^2}
\end{align}
$$


<span class = "myhighlight2">Definition 2. Clusters</span> A cluster is a collection of points that are part of the same group. For k-means, every point is part of a cluster. So as the algorithm progresses and the centroids shift, points might change which cluster they're grouped in, even though the point itself does not move. 

<span class = "myhighlight2">Definition 3. Centroids</span> A centroid is the center of a cluster calculated by the average location of all the cluster points. This is equivalent to the average of the data points' components in each dimension. So if we have three $n$-dimensional points $a$, $b$, and $c$, we define the average as


$$
\small
\mathrm{average} = 
\left[
\tfrac{a_1 + b_1 + c_1}{3}, \tfrac{a_2 + b_2 + c_2}{3}, \tfrac{a_3 + b_3 + c_3}{3}
\right]
$$

<span class = "myhighlight2">Definition 4. Convergence</span> An algorithm converges if the locations of all centroids do not change much between two iterations, e.g. within some threshold of $1 \times 10^{-5}$.





### KNN Algorithm



The KNN algorithm [@leonardomauroSpotifySongsSimilarity2020] searches for $k$ similar elements based on a query point at the center within a predefined radius. The Euclidean distance between two points is the length of the line segment between the two points. In this sense, the closer the distance is to 0, the more similar the songs are.



<div class = "roundedlist">
K-means clustering works in four steps:

1. Initialize some number $k$ of cluster centers, also called `centroids`.
2. For each data point in the dataset, assign it to the closest centroid.
3. Update the locations of the centroids to be the average of all the points assigned to that cluster.
4. Repeat steps 2 and 3 until convergence.

</div>


Note that the actual data points do not change. Only the locations of the centroids change with each iteration. And as the centroids move, the set containing the data points closest to each centroid alters.




### KNN Query Example



Our function allows us to create personalized query points and modify the columns to explore other options. For example, the following code selects a specific set of song attributes and then searches for the $k$ highest values of these attributes set equal to one. Let's search for  $k=3$  similar songs to a query point $\textrm{songIndex} = 6$. 


```{python, echo=TRUE}
# Select song and column attributes
query_point = 4
columns = ['acousticness','danceability','energy','instrumentalness','liveness','speechiness','valence']
# Set parameters and run query
func, param = knnQuery, 3
response = querySimilars(df, columns, query_point, func, param)
```


```{python}
print('---- Query Point ----')
print(getMusicName(df.loc[query_point]))

print('---- k = 3 similar songs ----')
for track_index in response[0]:
    track_name = getMusicName(df.loc[track_index])
    print(track_name)

print('---- k = 3 nonsimilar songs ----')
for track_index in response[1]:
    track_name = getMusicName(df.loc[track_index])
    print(track_name)
```


\ 



The code below implements the same idea as above, but queries each track in a given playlist instead of a single defined query point.




```{python, echo=TRUE}
similar_count = {} # Similar songs count
nonsimilar_count = {} # Non-similar songs count
for track_index in df.index:
    response = querySimilars(df, columns, track_index, func, param)
    for similar_index in response[0]: # Get similar songs
        track = getMusicName(df.loc[similar_index])
        if track in similar_count:
            similar_count[track] += 1
        else:
            similar_count[track] = 1
    for nonsimilar_index in response[1]: # Get non-similar songs
        track = getMusicName(df.loc[nonsimilar_index])
        if track in nonsimilar_count:
            nonsimilar_count[track] += 1
        else:
            nonsimilar_count[track] = 1
```



```{python}
nonsimilar = dict(sorted(nonsimilar_count.items(), key=lambda item: item[1], reverse=True))

print('---- NON-SIMILAR SONGS COUNT ----')
for track_name, track_count in nonsimilar.items():
    if track_count >= 8:
        print(track_name, ':', track_count)
```









-------------------------


## Part 4. K Means Clustering


Next, we implement the K-Means clustering algorithm using the Scikit-Learn library to break down a playlist into several smaller playlists. The unsupervised learning algorithm divides similar data points into k groups by computing the distance to the centroid. 


The first step is to define an appropriate predefined number (k) of clusters. We use the Elbow Method to determine the optimal k, as shown below [@chingisoinarSeparateYourSaved2020].


```{python}
my_df = pd.read_csv('scripts/data/my_playlist.csv', encoding_errors='ignore', index_col=0, header=0)
X = my_df[['acousticness', 'danceability', 'liveness', 'energy','valence', 'instrumentalness', 'speechiness']]
features = X.values

from sklearn.cluster import KMeans
ssd = [] # Sum of squared distances
for k in range(1,11):
    model = KMeans(n_clusters = k, init="k-means++")
    model = model.fit(features)
    ssd.append(model.inertia_)
```




```{r,out.width="90%"}
elbowdf <- data.frame("ssd" = py$ssd,"x" = c(1:10))
elbow_plot <- ggplot(data = elbowdf, mapping = aes(x=x,y=ssd**2)) +
  geom_point(fill="#61cad1",pch = 21, size = 3.25, alpha = 0.9, color = "#030404", stroke = 0.5) + geom_line() +
  theme_ipsum_rc(axis_text_size = 10) +
  xlab("# clusters") + scale_x_continuous(n.breaks = 10) +
  ylab("sum of squared distances") + scale_y_continuous(n.breaks = 10)



ragg::agg_png(filename = "assets/static/elbow_plot.png", width = 7085, height = 4295, units = "px", res = 900)
elbow_plot
invisible(dev.off())
knitr::include_graphics("assets/static/elbow_plot.png")
```


Thus, we tune the clustering algorithm by running K-Means for a range of k values, obtaining the above figure. It looks like a value of 3 is optimal for this case. Next, we call the K-Means function and set the k value to 3 clusters.





```{python, echo=TRUE}
from sklearn.cluster import KMeans
model = KMeans(n_clusters = 3)
model = model.fit(features)
my_df['cluster'] = list(model.labels_)
```





```{python}
import seaborn as sns
sns.countplot([str(group) for group in model.labels_], color = 'lightblue')
```




Considering that there are seven different audio features for the clustering task, we use principal component analysis (PCA) to reduce the dimensionality of the data into a more easily visualized set of variables. 



```{python, echo=TRUE}
from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
pca_result = pca.fit_transform(features)
```



In the above code, we define a PCA instance to find two principal components determined from the features of the data. From there, we visualize the resulting clusters and explore the variation. The figure below shows our 3 clusters represented in 2-dimensional space.




```{r,echo=FALSE,eval=TRUE}
cluster_labels = c()
for (i in py$model$labels_) {
  cluster_labels = append(x = cluster_labels, values = glue::glue("Group ", i))}
x <- py$pca_result
pcadf <- data.frame("x1" = x[,1], "x2" = x[,2], "labels"=cluster_labels)


data_points_plot <- ggplot(data = pcadf, mapping = aes(x = x1, y = x2, label = cluster_labels)) +
  geom_point(mapping = aes(fill = cluster_labels), pch = 21, size = 3.85, alpha = 0.85, color = "#030404", stroke = 0.65) +
  scale_fill_manual(values = c(
    "black", "#61cad1", "#cae278", "#ff99b1",
    "#F0BE43", "#c757c7", "#ff5370")) +
  theme_ipsum_rc(axis_text_size = 10) +
  xlab(glue::glue("PCA ", round(py$pca$explained_variance_ratio_[1],digits = 5))) +
  ylab(glue::glue("PCA ", round(py$pca$explained_variance_ratio_[2],digits = 5)))


ragg::agg_png(filename = "assets/static/data_points_plot.png", width = 7085, height = 4295, units = "px", res = 900)
data_points_plot
invisible(dev.off())
knitr::include_graphics("assets/static/data_points_plot.png")
```










```{python}
my_df = my_df[['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'valence','cluster']]
my_df = my_df.astype({'cluster': str})

means = pd.DataFrame(index = range(0,3), columns = list(my_df[my_df['cluster'] == '0'].describe().loc['mean'].index))

means.iloc[0] = my_df[my_df['cluster'] == '0'].describe().loc['mean']
means.iloc[1] = my_df[my_df['cluster'] == '1'].describe().loc['mean']
means.iloc[2] = my_df[my_df['cluster'] == '2'].describe().loc['mean']

```





```{r}
py$means %>% kable(row.names = 1:nrow(py$means)) %>%
  kable_styling(full_width = FALSE)
```



- Cluster 1 has the highest energy and valence, indicating that these tracks are faster-paced, louder, and more positive (e.g., happy, cheerful, euphoric) than the other clusters. 
- Cluster 2 has the highest acousticness, with a mean value of 0.5396875 over all the cluster's songs. Cluster 2 is also higher in danceability, indicating tracks with a faster tempo and beat intensity. 
- Cluster 3 appears to be the lowest valence, with a mean of 0.2303227, indicating more negative trajectories (e.g., sadness, frustration, anger). 
- All the clusters have values below 0.33, indicating that the songs most likely represent music and other non-speech-like tracks.




-------------------------


## References


