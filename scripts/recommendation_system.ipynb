{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3c5dca",
   "metadata": {},
   "source": [
    "##  Spotify Song Recommendation System\n",
    "\n",
    "We implement a content-based filtering approach for Spotify Song recommendation based on a [medium article](https://towardsdatascience.com/part-iii-building-a-song-recommendation-system-with-spotify-cf76b52705e7) for building a Spotify song recommendation system series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1dfa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from operator import index\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e361012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New Music Friday      100\n",
       "New Pop Picks         100\n",
       "just hits             100\n",
       "Hip Hop Controller     99\n",
       "RapCaviar              51\n",
       "Today's Top Hits       50\n",
       "Hot Hits USA           50\n",
       "Name: playlist, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playlist_data = pd.read_csv(\"data/spotify.csv\")\n",
    "\n",
    "spotify_playlists = pd.read_csv('data/spotify_playlists.csv', encoding_errors='ignore', index_col=0, header=0)\n",
    "spotify_playlists['playlist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78885c",
   "metadata": {},
   "source": [
    "First, we want to check for song duplicates in the playlist. The following code uses the `drop_duplicates` function in **pandas** to drop duplicate songs while building an underlying dataframe with all unique content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a729c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates of songs accross playlists\n",
    "playlistDF = df.copy(deep = True)\n",
    "playlistDF[['artist','name','playlist']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop song duplicates\n",
    "def drop_duplicates(df):\n",
    "    df['artists_song']=df.apply(lambda row: row['artist']+' - '+row['name'],axis=1)\n",
    "    return df.drop_duplicates('artists_song')\n",
    "\n",
    "songDF = drop_duplicates(playlistDF)\n",
    "print(len(pd.unique(songDF.artists_song)) == len(songDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d2d84",
   "metadata": {},
   "source": [
    "For the audio features, we can categorize each attribute into four general categories as follows.\n",
    "\n",
    "- **Mood**: Danceability, Energy, Tempo, Valence\n",
    "- **Properties**: Instrumentalness, Loudness, Speechiness\n",
    "- **Context**: Acousticness, Liveness\n",
    "- **Metadata**: key, mode, time_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "songDF = songDF[[\n",
    "    'name', 'track_id', 'release_date', 'popularity', # Track Metadata\n",
    "    'artist', 'artist_id', 'artist_pop', 'artist_genres', # Artist Info\n",
    "    'danceability', 'energy', 'valence', 'tempo', # Audio Features - Mood\n",
    "    'instrumentalness', 'loudness', 'speechiness', # Audio Features - Properties\n",
    "    'acousticness', 'liveness', # Audio Features - Context\n",
    "    'key', 'mode', 'time_signature' # Audio Features - Metadata\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be82e7",
   "metadata": {},
   "source": [
    "### Feature Generation\n",
    "\n",
    "\n",
    "Data feature engineering methods are an integral part of recommender systems. We implement the following process into the feature generation pipeline. \n",
    "\n",
    "#### 1. Sentiment Analysis\n",
    "\n",
    "The following code performs a simple sentiment analysis using the subjectivity and polarity forms from the TextBlob package. Subjectivity, on a scale from 0 to 1, is the amount of personal opinion and factual information in the text. Polarity, on a scale from -1 to 1, is the degree of sentimentality that leads to negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subjectivity & polarity using textblob\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Categorize polarity & subjectivity score\n",
    "def getAnalysis(score, task=\"polarity\"):\n",
    "    if task == \"subjectivity\":\n",
    "        if score < 1/3:\n",
    "            return \"low\"\n",
    "        elif score > 1/3:\n",
    "            return \"high\"\n",
    "        else:\n",
    "            return \"medium\"\n",
    "    else:\n",
    "        if score < 0:\n",
    "            return 'Negative'\n",
    "        elif score == 0:\n",
    "            return 'Neutral'\n",
    "        else:\n",
    "            return 'Positive'\n",
    "\n",
    "# Perform sentiment analysis on text\n",
    "def sentiment_analysis(df, text_col):\n",
    "    df['subjectivity'] = df[text_col].apply(getSubjectivity).apply(lambda x: getAnalysis(x,\"subjectivity\"))\n",
    "    df['polarity'] = df[text_col].apply(getPolarity).apply(getAnalysis)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a264b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentDF = sentiment_analysis(songDF, \"name\")\n",
    "sentimentDF[['name', 'artist', 'subjectivity', 'polarity']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45e4e3",
   "metadata": {},
   "source": [
    "#### 2. One-Hot Encoding\n",
    "\n",
    "We now use one-hot encoding to include the sentiment of a song as input. One-hot encoding converts categorical variables into a syntactic form that machines can understand. The first step involves converting each category into a column representing either True or False. \n",
    "\n",
    "\n",
    "![](https://iq.opengenus.org/content/images/2022/01/TW5m0aJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create One Hot Encoded features of a specific column\n",
    "def ohe_prep(df, column, new_name):\n",
    "    tf_df = pd.get_dummies(df[column])\n",
    "    feature_names = tf_df.columns\n",
    "    tf_df.columns = [new_name + \"|\" + str(i) for i in feature_names]\n",
    "    tf_df.reset_index(drop = True, inplace = True)    \n",
    "    \n",
    "    return tf_df # One-hot encoded features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for the subjectivity \n",
    "subject_ohe = ohe_prep(sentimentDF, 'subjectivity','subject')\n",
    "subject_ohe.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2787a5",
   "metadata": {},
   "source": [
    "#### 3. TF-IDF\n",
    "\n",
    "\n",
    "\n",
    "Spotify's genres are imbalanced, with some more prevalent than others. Therefore, we weigh the importance of each genre to prevent overemphasizing some types and underestimating others. \n",
    "\n",
    "The Term Frequency-Inverse Document Frequency (TF-IDF) quantifies words in a set of documents, showing the importance of a word in the corpus: $ \\text{Term Frequency}\\times\\text{Inverse Document Frequency}$.\n",
    "\n",
    "\n",
    "The term frequency (TF) is the number of times a term appears in each document divided by the total word count, and the inverse document frequency (IDF) is the log value of the document frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a90361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF implementation\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix =  tfidf.fit_transform(songDF['artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# Genres dataframe\n",
    "genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "genre_df.columns = ['genre' + \"|\" + i for i in tfidf.get_feature_names()]\n",
    "genre_df.reset_index(drop = True, inplace=True)\n",
    "genre_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff271506",
   "metadata": {},
   "source": [
    "#### 4. Normalization\n",
    "\n",
    "\n",
    "We need to normalize the popularity variable and audio features from 0 to 1. We use the MinMaxScaler function from scikit-learn, which automatically scales all values in min and max to the range 0 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640458e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist_pop distribution descriptive stats\n",
    "print(songDF['artist_pop'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e0769",
   "metadata": {},
   "source": [
    "Next, we apply hyperparameter tuning to the audio features of a song to improve the prediction. Specifically, the normalization of this data stems from the maximum and minimum values of each attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f79243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "pop = songDF[[\"artist_pop\"]].reset_index(drop = True)\n",
    "scaler = MinMaxScaler()\n",
    "pop_scaled = pd.DataFrame(scaler.fit_transform(pop), columns = pop.columns)\n",
    "pop_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc6c59",
   "metadata": {},
   "source": [
    "#### Feature Generation\n",
    "\n",
    "Finally, we use the following code to generate all the above features and concatenate all the variables into a new data frame. We define the following function to process and create a final set of features to generate recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ebd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_set(df, float_cols):\n",
    "    \n",
    "    # Tfidf genre lists\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix =  tfidf.fit_transform(df['artist_genres'].apply(lambda x: \" \".join(x)))\n",
    "    genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "    genre_df.columns = ['genre' + \"|\" + i for i in tfidf.get_feature_names()]\n",
    "    genre_df.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    df = sentiment_analysis(df, \"name\")\n",
    "\n",
    "    # One-hot encoding\n",
    "    subject_ohe = ohe_prep(df, 'subjectivity','subject') * 0.3\n",
    "    polar_ohe = ohe_prep(df, 'polarity','polar') * 0.5\n",
    "    key_ohe = ohe_prep(df, 'key','key') * 0.5\n",
    "    mode_ohe = ohe_prep(df, 'mode','mode') * 0.5\n",
    "\n",
    "    # Normalization - scale popularity columns\n",
    "    pop = df[[\"artist_pop\",\"popularity\"]].reset_index(drop = True)\n",
    "    scaler = MinMaxScaler()\n",
    "    pop_scaled = pd.DataFrame(scaler.fit_transform(pop), columns = pop.columns) * 0.2 \n",
    "\n",
    "    # Scale audio feature columns\n",
    "    floats = df[float_cols].reset_index(drop = True)\n",
    "    scaler = MinMaxScaler()\n",
    "    floats_scaled = pd.DataFrame(scaler.fit_transform(floats), columns = floats.columns) * 0.2\n",
    "\n",
    "    # Concanenate all features\n",
    "    final = pd.concat([genre_df, floats_scaled, pop_scaled, subject_ohe, polar_ohe, key_ohe, mode_ohe], axis = 1)\n",
    "    final.insert(loc=0, column='track_id', value=df['track_id'].values) # Add song name\n",
    "    \n",
    "    return final # Final set of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data and generate features\n",
    "float_cols = songDF.dtypes[songDF.dtypes == 'float64'].index.values\n",
    "complete_feature_set = create_feature_set(songDF, float_cols=float_cols)\n",
    "\n",
    "# songDF.to_csv(\"../data/allsong_data.csv\", index = False)\n",
    "#complete_feature_set.to_csv(\"../data/complete_feature.csv\", index = False)\n",
    "complete_feature_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6c963",
   "metadata": {},
   "source": [
    "### Content-based Filtering Recommendation\n",
    "\n",
    "\n",
    "The next step is to perform content-based filtering based on the song features. To do so, we concatenate all songs in a playlist into one summarization vector. Then, we find the similarity between the summarized playlist vector with all songs (not including the songs in the playlist) in the database. Then, we use the similarity measure retrieved the most relevant song that is not in the playlist to recommend it.\n",
    "\n",
    "\n",
    "\n",
    "#### Choose Playlist\n",
    "\n",
    "\n",
    "In this part, we test the data with *Mom's playlist* in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c55468",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = playlistDF[playlistDF['playlist'] == \"but my feet in bottega\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5a825",
   "metadata": {},
   "source": [
    "#### Extract features\n",
    "\n",
    "The next step is to generate the features. We need to first use the `id` to differentiate songs that are in the playlist and those that are not. Then, we simply add the features for all songs in the playlist together as a summary vector.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize playlist into a single vector\n",
    "def generate_playlist_feature(feat_set, playlist_df):\n",
    "    \n",
    "    # Find song features in the playlist\n",
    "    feat_set_playlist = feat_set[feat_set['track_id'].isin(playlist_df['track_id'].values)]    \n",
    "    \n",
    "    # Find all non-playlist song features\n",
    "    feat_set_nonplaylist = feat_set[~feat_set['track_id'].isin(playlist_df['track_id'].values)]\n",
    "    feat_set_playlist_final = feat_set_playlist.drop(columns = \"track_id\")\n",
    "    \n",
    "    # Single vector feature summarizing playlist\n",
    "    return feat_set_playlist_final.sum(axis = 0), feat_set_nonplaylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b2586",
   "metadata": {},
   "source": [
    "> In other words, this vector describes the whole playlist as if it is one song.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9149199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the features\n",
    "feat_set_pl, feat_set_nonpl = generate_playlist_feature(complete_feature_set, testDF)\n",
    "# Non-playlist features feat_set_nonpl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarized playlist features\n",
    "complete_feature_set\n",
    "feat_set_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008df64",
   "metadata": {},
   "source": [
    "\n",
    "#### Find similarity\n",
    "\n",
    "In our code, we used the `cosine_similarity()` function from `scikit learn` to measure the similarity between each song and the summarized playlist vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated recommendation based on songs in aspecific playlist\n",
    "def generate_playlist_recos(df, features, nonplaylist_features):\n",
    "    '''\n",
    "    features (pandas series): summarized playlist feature (single vector)\n",
    "    nonplaylist_features (pandas dataframe): feature set of songs that are not in the selected playlist\n",
    "    '''\n",
    "    \n",
    "    non_playlist_df = df[df['id'].isin(nonplaylist_features['id'].values)]\n",
    "    # Find cosine similarity between the playlist and the complete song set\n",
    "    non_playlist_df['sim'] = cosine_similarity(nonplaylist_features.drop('id', axis = 1).values, features.values.reshape(1, -1))[:,0]\n",
    "    non_playlist_df_top_40 = non_playlist_df.sort_values('sim',ascending = False).head(40)\n",
    "    \n",
    "    # Top 40 recommendations for that playlist\n",
    "    return non_playlist_df_top_40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bdb316",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f41697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_playlist(api_results,sp = None, append_audio = True):\n",
    "    \n",
    "    # DataFrame with track_name, track_id, artist, album, duration, popularity\n",
    "    df = create_df_saved_songs(api_results[\"tracks\"])\n",
    "    \n",
    "    # Whether to append audio features\n",
    "    if append_audio == True:\n",
    "        assert sp != None, \"sp needs to be specified for appending audio features\"\n",
    "        df = append_audio_features(df,sp)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def append_audio_features(df,spotify_auth, return_feat_df = False):\n",
    "    \"\"\" \n",
    "    Fetches the audio features for all songs in a DataFrame and\n",
    "    appends these as rows to the DataFrame.\n",
    "    Requires spotipy to be set up with an auth token.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe containing at least track_name and track_id for spotify songs\n",
    "    spotify_auth: spotfiy authentication token (result of authenticate())\n",
    "    return_feat_df: argument to choose whether to also return df with just the audio features\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df: DataFrame containing all original rows and audio features for each song\n",
    "    df_features(optional): DataFrame containing just the audio features\n",
    "    \"\"\"\n",
    "    audio_features = spotify_auth.audio_features(df[\"track_id\"][:])\n",
    "    assert len(audio_features) == len(df[\"track_id\"][:])\n",
    "    feature_cols = list(audio_features[0].keys())[:-7]\n",
    "    features_list = []\n",
    "    for features in audio_features:\n",
    "        try:\n",
    "            song_features = [features[col] for col in feature_cols]\n",
    "            features_list.append(song_features)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    df_features = pd.DataFrame(features_list,columns = feature_cols)\n",
    "    df = pd.concat([df,df_features],axis = 1)\n",
    "    if return_feat_df == False:\n",
    "        return df\n",
    "    else:\n",
    "        return df,df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get playlist data from API\n",
    "playlist_uri = \"INSERT YOUR SPOTIFY PLAYLIST URI\"\n",
    "playlist_df = create_df_playlist(playlist, sp = sp)\n",
    "# Get seed tracks for recommendations\n",
    "seed_tracks = playlist_df[\"track_id\"].tolist()\n",
    "\n",
    "#create recommendation df from multiple recommendations\n",
    "recomm_dfs = []\n",
    "for i in range(5,len(seed_tracks)+1,5):\n",
    "    recomms = sp.recommendations(seed_tracks = seed_tracks[i-5:i],limit = 25)\n",
    "    recomms_df = append_audio_features(create_df_recommendations(recomms),sp)\n",
    "    recomm_dfs.append(recomms_df)\n",
    "recomms_df = pd.concat(recomm_dfs)\n",
    "recomms_df.reset_index(drop = True, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
